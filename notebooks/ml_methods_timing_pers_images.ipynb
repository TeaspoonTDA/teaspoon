{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zero_dim_rtl</th>\n",
       "      <th>zero_dim_ltr</th>\n",
       "      <th>zero_dim_btt</th>\n",
       "      <th>zero_dim_ttb</th>\n",
       "      <th>one_dim_rtl</th>\n",
       "      <th>one_dim_ltr</th>\n",
       "      <th>one_dim_btt</th>\n",
       "      <th>one_dim_ttb</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[23.0, 50.0], [13.0, 20.0]]</td>\n",
       "      <td>[[24.0, 50.0], [11.0, 21.0]]</td>\n",
       "      <td>[[24.0, 50.0], [8.0, 9.0]]</td>\n",
       "      <td>[[23.0, 50.0]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[22.0, 50.0]]</td>\n",
       "      <td>[[22.0, 50.0]]</td>\n",
       "      <td>[[23.0, 50.0]]</td>\n",
       "      <td>[[24.0, 50.0]]</td>\n",
       "      <td>[[0.0, 8.0]]</td>\n",
       "      <td>[[0.0, 8.0]]</td>\n",
       "      <td>[[0.0, 9.0]]</td>\n",
       "      <td>[[0.0, 8.0]]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[22.0, 50.0]]</td>\n",
       "      <td>[[25.0, 50.0]]</td>\n",
       "      <td>[[24.0, 50.0], [15.0, 16.0]]</td>\n",
       "      <td>[[23.0, 50.0], [13.0, 22.0]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[21.0, 50.0]]</td>\n",
       "      <td>[[20.0, 50.0]]</td>\n",
       "      <td>[[24.0, 50.0]]</td>\n",
       "      <td>[[23.0, 50.0]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[20.0, 50.0], [16.0, 18.0]]</td>\n",
       "      <td>[[22.0, 50.0], [14.0, 15.0]]</td>\n",
       "      <td>[[26.0, 50.0]]</td>\n",
       "      <td>[[21.0, 50.0]]</td>\n",
       "      <td>[[0.0, 9.0]]</td>\n",
       "      <td>[[0.0, 12.0]]</td>\n",
       "      <td>[[0.0, 9.0]]</td>\n",
       "      <td>[[0.0, 14.0]]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>[[23.0, 50.0], [16.0, 17.0]]</td>\n",
       "      <td>[[22.0, 50.0], [16.0, 18.0]]</td>\n",
       "      <td>[[24.0, 50.0]]</td>\n",
       "      <td>[[23.0, 50.0]]</td>\n",
       "      <td>[[0.0, 13.0], [0.0, 7.0]]</td>\n",
       "      <td>[[0.0, 13.0], [0.0, 9.0]]</td>\n",
       "      <td>[[0.0, 16.0], [0.0, 6.0]]</td>\n",
       "      <td>[[0.0, 17.0], [0.0, 5.0]]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>[[21.0, 50.0], [17.0, 18.0]]</td>\n",
       "      <td>[[24.0, 50.0], [12.0, 18.0], [9.0, 17.0]]</td>\n",
       "      <td>[[23.0, 50.0]]</td>\n",
       "      <td>[[24.0, 50.0], [7.0, 10.0]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>[[24.0, 50.0], [13.0, 18.0]]</td>\n",
       "      <td>[[23.0, 50.0], [12.0, 20.0]]</td>\n",
       "      <td>[[24.0, 50.0]]</td>\n",
       "      <td>[[23.0, 50.0], [5.0, 7.0]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>[[23.0, 50.0], [8.0, 21.0]]</td>\n",
       "      <td>[[22.0, 50.0], [11.0, 15.0]]</td>\n",
       "      <td>[[21.0, 50.0]]</td>\n",
       "      <td>[[26.0, 50.0], [8.0, 15.0]]</td>\n",
       "      <td>[[0.0, 17.0]]</td>\n",
       "      <td>[[0.0, 8.0]]</td>\n",
       "      <td>[[0.0, 15.0]]</td>\n",
       "      <td>[[0.0, 10.0]]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>[[25.0, 50.0]]</td>\n",
       "      <td>[[22.0, 50.0]]</td>\n",
       "      <td>[[24.0, 50.0]]</td>\n",
       "      <td>[[22.0, 50.0], [19.0, 20.0]]</td>\n",
       "      <td>[[0.0, 11.0], [0.0, 8.0]]</td>\n",
       "      <td>[[0.0, 18.0], [0.0, 9.0]]</td>\n",
       "      <td>[[0.0, 20.0], [0.0, 8.0]]</td>\n",
       "      <td>[[0.0, 14.0], [0.0, 5.0]]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       zero_dim_rtl  \\\n",
       "0      [[23.0, 50.0], [13.0, 20.0]]   \n",
       "1                    [[22.0, 50.0]]   \n",
       "2                    [[22.0, 50.0]]   \n",
       "3                    [[21.0, 50.0]]   \n",
       "4      [[20.0, 50.0], [16.0, 18.0]]   \n",
       "...                             ...   \n",
       "59995  [[23.0, 50.0], [16.0, 17.0]]   \n",
       "59996  [[21.0, 50.0], [17.0, 18.0]]   \n",
       "59997  [[24.0, 50.0], [13.0, 18.0]]   \n",
       "59998   [[23.0, 50.0], [8.0, 21.0]]   \n",
       "59999                [[25.0, 50.0]]   \n",
       "\n",
       "                                    zero_dim_ltr  \\\n",
       "0                   [[24.0, 50.0], [11.0, 21.0]]   \n",
       "1                                 [[22.0, 50.0]]   \n",
       "2                                 [[25.0, 50.0]]   \n",
       "3                                 [[20.0, 50.0]]   \n",
       "4                   [[22.0, 50.0], [14.0, 15.0]]   \n",
       "...                                          ...   \n",
       "59995               [[22.0, 50.0], [16.0, 18.0]]   \n",
       "59996  [[24.0, 50.0], [12.0, 18.0], [9.0, 17.0]]   \n",
       "59997               [[23.0, 50.0], [12.0, 20.0]]   \n",
       "59998               [[22.0, 50.0], [11.0, 15.0]]   \n",
       "59999                             [[22.0, 50.0]]   \n",
       "\n",
       "                       zero_dim_btt                  zero_dim_ttb  \\\n",
       "0        [[24.0, 50.0], [8.0, 9.0]]                [[23.0, 50.0]]   \n",
       "1                    [[23.0, 50.0]]                [[24.0, 50.0]]   \n",
       "2      [[24.0, 50.0], [15.0, 16.0]]  [[23.0, 50.0], [13.0, 22.0]]   \n",
       "3                    [[24.0, 50.0]]                [[23.0, 50.0]]   \n",
       "4                    [[26.0, 50.0]]                [[21.0, 50.0]]   \n",
       "...                             ...                           ...   \n",
       "59995                [[24.0, 50.0]]                [[23.0, 50.0]]   \n",
       "59996                [[23.0, 50.0]]   [[24.0, 50.0], [7.0, 10.0]]   \n",
       "59997                [[24.0, 50.0]]    [[23.0, 50.0], [5.0, 7.0]]   \n",
       "59998                [[21.0, 50.0]]   [[26.0, 50.0], [8.0, 15.0]]   \n",
       "59999                [[24.0, 50.0]]  [[22.0, 50.0], [19.0, 20.0]]   \n",
       "\n",
       "                     one_dim_rtl                one_dim_ltr  \\\n",
       "0                             []                         []   \n",
       "1                   [[0.0, 8.0]]               [[0.0, 8.0]]   \n",
       "2                             []                         []   \n",
       "3                             []                         []   \n",
       "4                   [[0.0, 9.0]]              [[0.0, 12.0]]   \n",
       "...                          ...                        ...   \n",
       "59995  [[0.0, 13.0], [0.0, 7.0]]  [[0.0, 13.0], [0.0, 9.0]]   \n",
       "59996                         []                         []   \n",
       "59997                         []                         []   \n",
       "59998              [[0.0, 17.0]]               [[0.0, 8.0]]   \n",
       "59999  [[0.0, 11.0], [0.0, 8.0]]  [[0.0, 18.0], [0.0, 9.0]]   \n",
       "\n",
       "                     one_dim_btt                one_dim_ttb  labels  \n",
       "0                             []                         []       5  \n",
       "1                   [[0.0, 9.0]]               [[0.0, 8.0]]       0  \n",
       "2                             []                         []       4  \n",
       "3                             []                         []       1  \n",
       "4                   [[0.0, 9.0]]              [[0.0, 14.0]]       9  \n",
       "...                          ...                        ...     ...  \n",
       "59995  [[0.0, 16.0], [0.0, 6.0]]  [[0.0, 17.0], [0.0, 5.0]]       8  \n",
       "59996                         []                         []       3  \n",
       "59997                         []                         []       5  \n",
       "59998              [[0.0, 15.0]]              [[0.0, 10.0]]       6  \n",
       "59999  [[0.0, 20.0], [0.0, 8.0]]  [[0.0, 14.0], [0.0, 5.0]]       8  \n",
       "\n",
       "[60000 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from teaspoon.ML import load_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mnist = load_datasets.mnist()\n",
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Missing Data in One Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(dim_1):\n",
    "    for i in range(0, len(dim_1)):\n",
    "        if len(dim_1[i])== 0:\n",
    "            dim_1[i] = np.array([[0,.01]])\n",
    "        else: \n",
    "            dim_1[i] = dim_1[i]\n",
    "    return dim_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mnist['one_dim_rtl'] = fill_missing(mnist['one_dim_rtl'])\n",
    "mnist['one_dim_ltr'] = fill_missing(mnist['one_dim_ltr'])\n",
    "mnist['one_dim_btt'] = fill_missing(mnist['one_dim_btt'])\n",
    "mnist['one_dim_ttb'] = fill_missing(mnist['one_dim_ttb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Dimension for Timing Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_sklearn(DgmsFD, labels_col, train_size=.5, seed=12):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    labels = DgmsFD[labels_col]\n",
    "    training_dgms, testing_dgms = train_test_split(DgmsFD, train_size=train_size, random_state=seed, stratify=labels)\n",
    "    return training_dgms.reset_index(), testing_dgms.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms_train, dgms_test = train_test_split_sklearn(mnist, 'labels', train_size = .05)\n",
    "xdgm0_train = dgms_train['zero_dim_rtl']\n",
    "xdgm0_test = dgms_test['zero_dim_rtl']\n",
    "xdgm1_train = dgms_train['one_dim_rtl']\n",
    "xdgm1_test = dgms_test['one_dim_rtl']\n",
    "labels_train = dgms_train['labels']\n",
    "labels_test = dgms_test['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load original persistence images method function from teaspoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from persim import PersistenceImager\n",
    "import math\n",
    "from math import pi\n",
    "from numpy.linalg import norm as lnorm\n",
    "from sympy.abc import t\n",
    "from sympy import Piecewise\n",
    "from sympy import diff, integrate\n",
    "from itertools import combinations\n",
    "\n",
    "def F_Image(PD1, PS, var, plot, D_Img=[], pers_imager=None, training=True):\n",
    "    \n",
    "\n",
    "    output = {}\n",
    "    # number of persistence diagrams\n",
    "    N1 = len(PD1)\n",
    "\n",
    "    if training == True:\n",
    "        # adjust the image parameters and compute images\n",
    "        pers_imager = PersistenceImager()\n",
    "        pers_imager.pixel_size = PS\n",
    "        pers_imager.kernel_params = {'sigma': var}\n",
    "\n",
    "        PDs = PD1.tolist()\n",
    "        pers_imager.fit(PDs, skew=True)\n",
    "        pers_img = [pers_imager.transform(PD1[i], skew=True) for i in np.arange(0, N1, 1)]\n",
    "    else:\n",
    "        pers_img = [pers_imager.transform(PD1[i], skew=True) for i in np.arange(0, N1, 1)]\n",
    "\n",
    "    # generate feature matrix\n",
    "    feature_PI = np.zeros(\n",
    "        (N1, len(pers_img[0][:, 0])*len(pers_img[0][0, :])))\n",
    "    for i in range(N1):\n",
    "        feature_PI[i, :] = pers_img[i].flatten()\n",
    "\n",
    "    # plot all images or images of certain persistence diagrams\n",
    "    if plot == True:\n",
    "        fig = []\n",
    "        if D_Img == []:\n",
    "            D_Img = np.arange(1, 2, 1)\n",
    "        for i in range(len(D_Img)):\n",
    "            plt.figure()\n",
    "            ax = plt.gca()\n",
    "            pimgr = PersistenceImager()\n",
    "            pimgr.pixel_size = PS\n",
    "            pimgr.kernel_params = {'sigma': var}\n",
    "            pimgr.fit(PD1[D_Img[i]-1], skew=True)\n",
    "            imgs = pimgr.transform(PD1[D_Img[i]-1], skew=True)\n",
    "            pers_imager.plot_image(imgs, ax)\n",
    "            fig.append(plt.gcf())\n",
    "        output['figures'] = fig\n",
    "\n",
    "    output['F_Matrix'] = feature_PI\n",
    "    output['pers_imager'] = pers_imager\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "print(cpu_count)\n",
    "\n",
    "@jit\n",
    "def jit_F_Image(PD1, PS, var, plot, D_Img=[], pers_imager=None, training=True):\n",
    "    \n",
    "\n",
    "    output = {}\n",
    "    # number of persistence diagrams\n",
    "    N1 = len(PD1)\n",
    "\n",
    "    if training == True:\n",
    "        # adjust the image parameters and compute images\n",
    "        pers_imager = PersistenceImager()\n",
    "        pers_imager.pixel_size = PS\n",
    "        pers_imager.kernel_params = {'sigma': var}\n",
    "\n",
    "        PDs = PD1.tolist()\n",
    "        pers_imager.fit(PDs, skew=True)\n",
    "        pers_img = [pers_imager.transform(PD1[i], skew=True) for i in np.arange(0, N1, 1)]\n",
    "    else:\n",
    "        pers_img = [pers_imager.transform(PD1[i], skew=True) for i in np.arange(0, N1, 1)]\n",
    "\n",
    "    # generate feature matrix\n",
    "    feature_PI = np.zeros(\n",
    "        (N1, len(pers_img[0][:, 0])*len(pers_img[0][0, :])))\n",
    "    for i in range(N1):\n",
    "        feature_PI[i, :] = pers_img[i].flatten()\n",
    "\n",
    "    # plot all images or images of certain persistence diagrams\n",
    "    if plot == True:\n",
    "        fig = []\n",
    "        if D_Img == []:\n",
    "            D_Img = np.arange(1, 2, 1)\n",
    "        for i in range(len(D_Img)):\n",
    "            plt.figure()\n",
    "            ax = plt.gca()\n",
    "            pimgr = PersistenceImager()\n",
    "            pimgr.pixel_size = PS\n",
    "            pimgr.kernel_params = {'sigma': var}\n",
    "            pimgr.fit(PD1[D_Img[i]-1], skew=True)\n",
    "            imgs = pimgr.transform(PD1[D_Img[i]-1], skew=True, njobs=cpu_count)\n",
    "            pers_imager.plot_image(imgs, ax)\n",
    "            fig.append(plt.gcf())\n",
    "        output['figures'] = fig\n",
    "\n",
    "    output['F_Matrix'] = feature_PI\n",
    "    output['pers_imager'] = pers_imager\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pers_imager = PersistenceImager()\n",
    "pers_imager.pixel_size = .1\n",
    "pers_imager.kernel_params = {'sigma': 1}\n",
    "\n",
    "pers_imager.fit(xdgm0_train, skew=True)\n",
    "imgs = pers_imager.transform(xdgm0_train, n_jobs=cpu_count)\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit imgs = pers_imager.transform(xdgm0_train, n_jobs=cpu_count)\n",
    "%timeit imgs = pers_imager.transform(xdgm0_train, n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "output0 = F_Image(xdgm0_train, PS=.1, var=1, plot=False, training=True)\n",
    "output1 = jit_F_Image(xdgm0_train, PS=.1, var=1, plot = False, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.6 ms Â± 350 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n",
      "18 ms Â± 195 Âµs per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit output0 = F_Image(xdgm0_train, PS=.1, var=1, plot=False, training=True)\n",
    "%timeit output1 = jit_F_Image(xdgm0_train, PS=.1, var=1, plot = False, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output1 = F_Image(xdgm0_train, PS=.1, var=1, plot=True, training=True, pers_imager=pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'figures': [<Figure size 640x480 with 1 Axes>],\n",
       " 'F_Matrix': array([[9.50975080e-046, 9.41520563e-046, 9.22892583e-046, ...,\n",
       "         3.54494212e-013, 2.92543767e-013, 2.44360088e-013],\n",
       "        [7.77072155e-286, 1.88306132e-284, 4.51779957e-283, ...,\n",
       "         0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n",
       "        [4.27383805e-046, 5.16731949e-046, 6.18547753e-046, ...,\n",
       "         0.00000000e+000, 2.77555756e-015, 0.00000000e+000],\n",
       "        ...,\n",
       "        [2.40851608e-041, 4.34281236e-041, 7.75270381e-041, ...,\n",
       "         2.27318164e-011, 1.71795911e-011, 1.28630440e-011],\n",
       "        [1.73933013e-262, 2.31397184e-261, 3.04785178e-260, ...,\n",
       "         3.72541997e-011, 2.08723039e-011, 1.15767396e-011],\n",
       "        [1.96092280e-048, 2.89530688e-048, 4.23242581e-048, ...,\n",
       "         8.05355782e-013, 4.07007761e-013, 2.04947170e-013]]),\n",
       " 'pers_imager': PersistenceImager(birth_range=(0.0, 26.0), pers_range=(1.0, 33.0), pixel_size=0.1, weight=persistence, weight_params={'n': 1.0}, kernel=gaussian, kernel_params={'sigma': 1})}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized with Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy.linalg import norm as lnorm\n",
    "from math import pi\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "@jit\n",
    "def optimizedKernelMethod(perDgm1, perDgm2, sigma):\n",
    "    L1 = len(perDgm1)\n",
    "    L2 = len(perDgm2)\n",
    "    kernel = np.zeros((L2, L1))\n",
    "\n",
    "    Kernel = 0\n",
    "\n",
    "    for i in range(0, L1):\n",
    "        p = perDgm1[i]\n",
    "        p = np.reshape(p, (2, 1))\n",
    "        for j in range(0, L2):\n",
    "            q = perDgm2[j]\n",
    "            q = np.reshape(q, (2, 1))\n",
    "            q_bar = np.zeros((2, 1))\n",
    "            q_bar[0] = q[1]\n",
    "            q_bar[1] = q[0]\n",
    "            dist1 = lnorm(p-q)\n",
    "            dist2 = lnorm(p-q_bar)\n",
    "            kernel[j, i] = np.exp(-(math.pow(dist1, 2))/(8*sigma)) - \\\n",
    "                np.exp(-(math.pow(dist2, 2))/(8*sigma))\n",
    "            Kernel = Kernel+kernel[j, i]\n",
    "    Kernel = Kernel*(1/(8*pi*sigma))\n",
    "\n",
    "    return Kernel\n",
    "\n",
    "@jit\n",
    "def optimized_heat_kernel_distance(dgm0, dgm1, sigma=.4):\n",
    "    return np.sqrt(optimizedKernelMethod(dgm0, dgm0, sigma) + optimizedKernelMethod(dgm1, dgm1, sigma) - 2*optimizedKernelMethod(dgm0, dgm1, sigma))\n",
    "\n",
    "@jit\n",
    "def optimized_kernel_features(train, s):\n",
    "    n_train = len(train)\n",
    "    X_train_features = np.zeros((n_train, n_train))\n",
    "    \n",
    "    for i in range(0,n_train):\n",
    "        for j in range(0,i):\n",
    "            dgm0 = train[i]\n",
    "            dgm1 = train[j]\n",
    "            hka = optimized_heat_kernel_distance(dgm0, dgm1, sigma = s) \n",
    "            X_train_features[i,j] = hka\n",
    "            X_train_features[j,i] = hka\n",
    "\n",
    "    return X_train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel with jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy.linalg import norm as lnorm\n",
    "from math import pi\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def par_optimized_kernel_features(train, s):\n",
    "    n_train = len(train)\n",
    "    for i in range(n_train):\n",
    "        for j in range(i):\n",
    "            dgm0 = train[train[:,0]==i,1:3]\n",
    "            dgm1 = train[train[:,0]==j,1:3]\n",
    "            kSigma0 = 0\n",
    "            kSigma1 = 0\n",
    "            kSigma2 = 0\n",
    "            sigma = s\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm0.shape[0]):\n",
    "                    q = dgm0[l,0:2]\n",
    "                    qc = dgm0[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma0 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm1.shape[0]):\n",
    "                p = dgm1[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma1 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma2 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "\n",
    "            kSigma0 = kSigma0/(8 * np.pi * sigma)\n",
    "            kSigma1 = kSigma1/(8 * np.pi * sigma)\n",
    "            kSigma2 = kSigma2/(8 * np.pi * sigma)\n",
    "            result[i,j] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)\n",
    "            result[j,i] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import guvectorize\n",
    "@guvectorize([\"void(float64[:,:], float64[:], float64, float64[:,:])\",],\"(m,n),(p),()->(p,p)\", target='parallel')\n",
    "def parallel_kernel_features_train(train, dummy, s, result):\n",
    "    n_train = len(dummy)\n",
    "    for i in range(n_train):\n",
    "        for j in range(i):\n",
    "            dgm0 = train[train[:,0]==i,1:3]\n",
    "            dgm1 = train[train[:,0]==j,1:3]\n",
    "            kSigma0 = 0\n",
    "            kSigma1 = 0\n",
    "            kSigma2 = 0\n",
    "            sigma = s\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm0.shape[0]):\n",
    "                    q = dgm0[l,0:2]\n",
    "                    qc = dgm0[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma0 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm1.shape[0]):\n",
    "                p = dgm1[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma1 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma2 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "\n",
    "            kSigma0 = kSigma0/(8 * np.pi * sigma)\n",
    "            kSigma1 = kSigma1/(8 * np.pi * sigma)\n",
    "            kSigma2 = kSigma2/(8 * np.pi * sigma)\n",
    "            result[i,j] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)\n",
    "            result[j,i] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import guvectorize\n",
    "@guvectorize([\"void(float64[:,:], float64[:], float64, float64[:,:])\",],\"(m,n),(p),()->(p,p)\", target='cpu')\n",
    "def gu_kernel_features_train(train, dummy, s, result):\n",
    "    n_train = len(dummy)\n",
    "    for i in range(n_train):\n",
    "        for j in range(i):\n",
    "            dgm0 = train[train[:,0]==i,1:3]\n",
    "            dgm1 = train[train[:,0]==j,1:3]\n",
    "            kSigma0 = 0\n",
    "            kSigma1 = 0\n",
    "            kSigma2 = 0\n",
    "            sigma = s\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm0.shape[0]):\n",
    "                    q = dgm0[l,0:2]\n",
    "                    qc = dgm0[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma0 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm1.shape[0]):\n",
    "                p = dgm1[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma1 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma2 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "\n",
    "            kSigma0 = kSigma0/(8 * np.pi * sigma)\n",
    "            kSigma1 = kSigma1/(8 * np.pi * sigma)\n",
    "            kSigma2 = kSigma2/(8 * np.pi * sigma)\n",
    "            result[i,j] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)\n",
    "            result[j,i] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_persistence_diagrams(dgm):\n",
    "    dgm_reshape = np.array([])\n",
    "    n = len(dgm)\n",
    "    for i in range(0,n):\n",
    "        t = np.repeat(i, len(dgm[i]))\n",
    "        t = t.reshape(len(dgm[i]),1)\n",
    "        t1 = np.concatenate((t,dgm[i]),1)\n",
    "        if i == 0:\n",
    "            dgm_reshape = t1\n",
    "        else:\n",
    "            dgm_reshape = np.append(dgm_reshape, t1, 0)\n",
    "    return dgm_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run to compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms_train, dgms_test = train_test_split_sklearn(mnist, 'labels', train_size = 10, seed=1)\n",
    "train_test = np.array(dgms_train['zero_dim_rtl'])\n",
    "X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "dummy_train = np.arange(len(train_test), dtype=np.float64)\n",
    "train = reshape_persistence_diagrams(train_test)\n",
    "result = parallel_kernel_features_train(train, dummy_train, .3)\n",
    "#X_train_features = par_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop for random samples and timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training  0\n",
      "Finished Training  1\n",
      "Finished Training  2\n"
     ]
    }
   ],
   "source": [
    "seed = [0,1,2,3,4,5,6,7,8,9]\n",
    "train_size = [.001, .005, .01, .05] # .01, .05]\n",
    "n = len(train_size)\n",
    "timing = np.zeros((n,4))\n",
    "for i in range(0,n):\n",
    "    for j in seed:\n",
    "        dgms_train, dgms_test = train_test_split_sklearn(mnist, 'labels', train_size = train_size[i], seed=j)\n",
    "        xdgm0_train = np.array(dgms_train['zero_dim_rtl'])\n",
    "        dummy_train = np.arange(len(xdgm0_train), dtype=np.float64)\n",
    "        train = reshape_persistence_diagrams(xdgm0_train)\n",
    "        timing[i,0] += len(xdgm0_train)\n",
    "\n",
    "        start = time.time()\n",
    "        result1 = gu_kernel_features_train(train, dummy_train, .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,1] +=end\n",
    "\n",
    "        start = time.time()\n",
    "        X_train_features = optimized_kernel_features(xdgm0_train, s = .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,2] +=end\n",
    "        start = time.time()\n",
    "        result3 = parallel_kernel_features_train(train, dummy_train, .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,3] +=end\n",
    "    print(\"Finished Training \", i)\n",
    "timing = pd.DataFrame(timing/10)\n",
    "timing.columns=['Observations', 'guvectorize', 'Jit optimized', 'Vectorized and Threading']\n",
    "print(timing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training  0\n",
      "Finished Training  1\n",
      "Finished Training  2\n",
      "Finished Training  3\n",
      "   Observations    Original  Jit optimized  Vectorized and Threading\n",
      "0          60.0    0.104926       0.010555                  0.001208\n",
      "1         300.0    2.637221       0.252662                  0.062772\n",
      "2         600.0   10.669852       1.033499                  0.413544\n",
      "3        3000.0  270.665288      27.861426                 46.286630\n"
     ]
    }
   ],
   "source": [
    "seed = [0,1,2,3,4,5,6,7,8,9]\n",
    "train_size = [.001, .005, .01, .05]\n",
    "n = len(train_size)\n",
    "timing = np.zeros((n,4))\n",
    "for i in range(0,n):\n",
    "    for j in seed:\n",
    "        dgms_train, dgms_test = train_test_split_sklearn(mnist, 'labels', train_size = train_size[i], seed=j)\n",
    "        xdgm0_train = np.array(dgms_train['zero_dim_rtl'])\n",
    "        timing[i,0] += len(xdgm0_train)\n",
    "        start = time.time()\n",
    "        X_train_features1 = kernel_features(xdgm0_train, s = .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,1] +=end\n",
    "        start = time.time()\n",
    "        X_train_features = optimized_kernel_features(xdgm0_train, s = .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,2] +=end\n",
    "        dummy_train = np.arange(len(xdgm0_train), dtype=np.float64)\n",
    "        train = reshape_persistence_diagrams(xdgm0_train)\n",
    "        start = time.time()\n",
    "        result3 = parallel_kernel_features_train(train, dummy_train, .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,3] +=end\n",
    "    print(\"Finished Training \", i)\n",
    "timing = pd.DataFrame(timing/10)\n",
    "timing.columns=['Observations', 'Original', 'Jit optimized', 'Vectorized and Threading']\n",
    "print(timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threading layer chosen: workqueue\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Threading layer chosen: %s\" % threading_layer())\n",
    "print(config.NUMBA_NUM_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45 s Â± 12.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "120 ms Â± 416 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n",
      "22.1 ms Â± 604 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:200]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "dummy_train = np.arange(len(train_test), dtype=np.float64)\n",
    "train = reshape_persistence_diagrams(train_test)\n",
    "%timeit numba_kernel_features_train(train, dummy_train, .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.24 s Â± 41.4 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "272 ms Â± 20.5 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "263 ms Â± 2.62 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:300]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.79 s Â± 114 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "468 ms Â± 2.24 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "466 ms Â± 774 Âµs per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:400]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.06 s Â± 238 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "731 ms Â± 10.7 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "729 ms Â± 7.56 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:500]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.1 s Â± 152 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "1.71 s Â± 143 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "1.66 s Â± 37.7 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:750]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.9 s Â± 773 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "2.98 s Â± 27 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "2.97 s Â± 12.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:1000]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.4 s Â± 524 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "4.67 s Â± 34.3 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "4.68 s Â± 24.4 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:1250]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 20s Â± 761 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "6.78 s Â± 81.8 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "6.81 s Â± 141 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:1500]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_test \u001b[39m=\u001b[39m xdgm0_train[\u001b[39m0\u001b[39m:\u001b[39m2000\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mtimeit\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtiming, X_train_features = kernel_features(np.array(train_test), s = .3)\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mtimeit\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtiming, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mtimeit\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtiming, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/development/teaspoon/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2417\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2416\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2417\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2419\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2420\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2421\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/development/teaspoon/.venv/lib/python3.9/site-packages/IPython/core/magics/execution.py:1170\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m):\n\u001b[1;32m   1169\u001b[0m     number \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m index\n\u001b[0;32m-> 1170\u001b[0m     time_number \u001b[39m=\u001b[39m timer\u001b[39m.\u001b[39;49mtimeit(number)\n\u001b[1;32m   1171\u001b[0m     \u001b[39mif\u001b[39;00m time_number \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m:\n\u001b[1;32m   1172\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/development/teaspoon/.venv/lib/python3.9/site-packages/IPython/core/magics/execution.py:158\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    156\u001b[0m gc\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     timing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(it, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimer)\n\u001b[1;32m    159\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[39mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;32m/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m dgm0 \u001b[39m=\u001b[39m train[i]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m dgm1 \u001b[39m=\u001b[39m train[j]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m hka \u001b[39m=\u001b[39m heat_kernel_distance(dgm0, dgm1, sigma \u001b[39m=\u001b[39;49m s) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m X_train_features[i,j] \u001b[39m=\u001b[39m hka\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m X_train_features[j,i] \u001b[39m=\u001b[39m hka\n",
      "\u001b[1;32m/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb Cell 21\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mheat_kernel_distance\u001b[39m(dgm0, dgm1, sigma\u001b[39m=\u001b[39m\u001b[39m.4\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msqrt(KernelMethod(dgm0, dgm0, sigma) \u001b[39m+\u001b[39m KernelMethod(dgm1, dgm1, sigma) \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m\u001b[39m*\u001b[39mKernelMethod(dgm0, dgm1, sigma))\n",
      "\u001b[1;32m/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m q_bar[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m q[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m q_bar[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m q[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m dist1 \u001b[39m=\u001b[39m lnorm(p\u001b[39m-\u001b[39;49mq)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m dist2 \u001b[39m=\u001b[39m lnorm(p\u001b[39m-\u001b[39mq_bar)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m kernel[j, i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m(math\u001b[39m.\u001b[39mpow(dist1, \u001b[39m2\u001b[39m))\u001b[39m/\u001b[39m(\u001b[39m8\u001b[39m\u001b[39m*\u001b[39msigma)) \u001b[39m-\u001b[39m \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m(math\u001b[39m.\u001b[39mpow(dist2, \u001b[39m2\u001b[39m))\u001b[39m/\u001b[39m(\u001b[39m8\u001b[39m\u001b[39m*\u001b[39msigma))\n",
      "File \u001b[0;32m~/development/teaspoon/.venv/lib/python3.9/site-packages/numpy/linalg/linalg.py:2553\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2551\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2552\u001b[0m     sqnorm \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mdot(x)\n\u001b[0;32m-> 2553\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[1;32m   2554\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n\u001b[1;32m   2555\u001b[0m     ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39mreshape(ndim\u001b[39m*\u001b[39m[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:2000]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
