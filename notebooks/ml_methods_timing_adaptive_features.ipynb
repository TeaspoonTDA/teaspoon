{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zero_dim_rtl</th>\n",
       "      <th>zero_dim_ltr</th>\n",
       "      <th>zero_dim_btt</th>\n",
       "      <th>zero_dim_ttb</th>\n",
       "      <th>one_dim_rtl</th>\n",
       "      <th>one_dim_ltr</th>\n",
       "      <th>one_dim_btt</th>\n",
       "      <th>one_dim_ttb</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[23.0, 50.0], [13.0, 20.0]]</td>\n",
       "      <td>[[24.0, 50.0], [11.0, 21.0]]</td>\n",
       "      <td>[[24.0, 50.0], [8.0, 9.0]]</td>\n",
       "      <td>[[23.0, 50.0]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[22.0, 50.0]]</td>\n",
       "      <td>[[22.0, 50.0]]</td>\n",
       "      <td>[[23.0, 50.0]]</td>\n",
       "      <td>[[24.0, 50.0]]</td>\n",
       "      <td>[[0.0, 8.0]]</td>\n",
       "      <td>[[0.0, 8.0]]</td>\n",
       "      <td>[[0.0, 9.0]]</td>\n",
       "      <td>[[0.0, 8.0]]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[22.0, 50.0]]</td>\n",
       "      <td>[[25.0, 50.0]]</td>\n",
       "      <td>[[24.0, 50.0], [15.0, 16.0]]</td>\n",
       "      <td>[[23.0, 50.0], [13.0, 22.0]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[21.0, 50.0]]</td>\n",
       "      <td>[[20.0, 50.0]]</td>\n",
       "      <td>[[24.0, 50.0]]</td>\n",
       "      <td>[[23.0, 50.0]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[20.0, 50.0], [16.0, 18.0]]</td>\n",
       "      <td>[[22.0, 50.0], [14.0, 15.0]]</td>\n",
       "      <td>[[26.0, 50.0]]</td>\n",
       "      <td>[[21.0, 50.0]]</td>\n",
       "      <td>[[0.0, 9.0]]</td>\n",
       "      <td>[[0.0, 12.0]]</td>\n",
       "      <td>[[0.0, 9.0]]</td>\n",
       "      <td>[[0.0, 14.0]]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>[[23.0, 50.0], [16.0, 17.0]]</td>\n",
       "      <td>[[22.0, 50.0], [16.0, 18.0]]</td>\n",
       "      <td>[[24.0, 50.0]]</td>\n",
       "      <td>[[23.0, 50.0]]</td>\n",
       "      <td>[[0.0, 13.0], [0.0, 7.0]]</td>\n",
       "      <td>[[0.0, 13.0], [0.0, 9.0]]</td>\n",
       "      <td>[[0.0, 16.0], [0.0, 6.0]]</td>\n",
       "      <td>[[0.0, 17.0], [0.0, 5.0]]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>[[21.0, 50.0], [17.0, 18.0]]</td>\n",
       "      <td>[[24.0, 50.0], [12.0, 18.0], [9.0, 17.0]]</td>\n",
       "      <td>[[23.0, 50.0]]</td>\n",
       "      <td>[[24.0, 50.0], [7.0, 10.0]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>[[24.0, 50.0], [13.0, 18.0]]</td>\n",
       "      <td>[[23.0, 50.0], [12.0, 20.0]]</td>\n",
       "      <td>[[24.0, 50.0]]</td>\n",
       "      <td>[[23.0, 50.0], [5.0, 7.0]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>[[23.0, 50.0], [8.0, 21.0]]</td>\n",
       "      <td>[[22.0, 50.0], [11.0, 15.0]]</td>\n",
       "      <td>[[21.0, 50.0]]</td>\n",
       "      <td>[[26.0, 50.0], [8.0, 15.0]]</td>\n",
       "      <td>[[0.0, 17.0]]</td>\n",
       "      <td>[[0.0, 8.0]]</td>\n",
       "      <td>[[0.0, 15.0]]</td>\n",
       "      <td>[[0.0, 10.0]]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>[[25.0, 50.0]]</td>\n",
       "      <td>[[22.0, 50.0]]</td>\n",
       "      <td>[[24.0, 50.0]]</td>\n",
       "      <td>[[22.0, 50.0], [19.0, 20.0]]</td>\n",
       "      <td>[[0.0, 11.0], [0.0, 8.0]]</td>\n",
       "      <td>[[0.0, 18.0], [0.0, 9.0]]</td>\n",
       "      <td>[[0.0, 20.0], [0.0, 8.0]]</td>\n",
       "      <td>[[0.0, 14.0], [0.0, 5.0]]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       zero_dim_rtl  \\\n",
       "0      [[23.0, 50.0], [13.0, 20.0]]   \n",
       "1                    [[22.0, 50.0]]   \n",
       "2                    [[22.0, 50.0]]   \n",
       "3                    [[21.0, 50.0]]   \n",
       "4      [[20.0, 50.0], [16.0, 18.0]]   \n",
       "...                             ...   \n",
       "59995  [[23.0, 50.0], [16.0, 17.0]]   \n",
       "59996  [[21.0, 50.0], [17.0, 18.0]]   \n",
       "59997  [[24.0, 50.0], [13.0, 18.0]]   \n",
       "59998   [[23.0, 50.0], [8.0, 21.0]]   \n",
       "59999                [[25.0, 50.0]]   \n",
       "\n",
       "                                    zero_dim_ltr  \\\n",
       "0                   [[24.0, 50.0], [11.0, 21.0]]   \n",
       "1                                 [[22.0, 50.0]]   \n",
       "2                                 [[25.0, 50.0]]   \n",
       "3                                 [[20.0, 50.0]]   \n",
       "4                   [[22.0, 50.0], [14.0, 15.0]]   \n",
       "...                                          ...   \n",
       "59995               [[22.0, 50.0], [16.0, 18.0]]   \n",
       "59996  [[24.0, 50.0], [12.0, 18.0], [9.0, 17.0]]   \n",
       "59997               [[23.0, 50.0], [12.0, 20.0]]   \n",
       "59998               [[22.0, 50.0], [11.0, 15.0]]   \n",
       "59999                             [[22.0, 50.0]]   \n",
       "\n",
       "                       zero_dim_btt                  zero_dim_ttb  \\\n",
       "0        [[24.0, 50.0], [8.0, 9.0]]                [[23.0, 50.0]]   \n",
       "1                    [[23.0, 50.0]]                [[24.0, 50.0]]   \n",
       "2      [[24.0, 50.0], [15.0, 16.0]]  [[23.0, 50.0], [13.0, 22.0]]   \n",
       "3                    [[24.0, 50.0]]                [[23.0, 50.0]]   \n",
       "4                    [[26.0, 50.0]]                [[21.0, 50.0]]   \n",
       "...                             ...                           ...   \n",
       "59995                [[24.0, 50.0]]                [[23.0, 50.0]]   \n",
       "59996                [[23.0, 50.0]]   [[24.0, 50.0], [7.0, 10.0]]   \n",
       "59997                [[24.0, 50.0]]    [[23.0, 50.0], [5.0, 7.0]]   \n",
       "59998                [[21.0, 50.0]]   [[26.0, 50.0], [8.0, 15.0]]   \n",
       "59999                [[24.0, 50.0]]  [[22.0, 50.0], [19.0, 20.0]]   \n",
       "\n",
       "                     one_dim_rtl                one_dim_ltr  \\\n",
       "0                             []                         []   \n",
       "1                   [[0.0, 8.0]]               [[0.0, 8.0]]   \n",
       "2                             []                         []   \n",
       "3                             []                         []   \n",
       "4                   [[0.0, 9.0]]              [[0.0, 12.0]]   \n",
       "...                          ...                        ...   \n",
       "59995  [[0.0, 13.0], [0.0, 7.0]]  [[0.0, 13.0], [0.0, 9.0]]   \n",
       "59996                         []                         []   \n",
       "59997                         []                         []   \n",
       "59998              [[0.0, 17.0]]               [[0.0, 8.0]]   \n",
       "59999  [[0.0, 11.0], [0.0, 8.0]]  [[0.0, 18.0], [0.0, 9.0]]   \n",
       "\n",
       "                     one_dim_btt                one_dim_ttb  labels  \n",
       "0                             []                         []       5  \n",
       "1                   [[0.0, 9.0]]               [[0.0, 8.0]]       0  \n",
       "2                             []                         []       4  \n",
       "3                             []                         []       1  \n",
       "4                   [[0.0, 9.0]]              [[0.0, 14.0]]       9  \n",
       "...                          ...                        ...     ...  \n",
       "59995  [[0.0, 16.0], [0.0, 6.0]]  [[0.0, 17.0], [0.0, 5.0]]       8  \n",
       "59996                         []                         []       3  \n",
       "59997                         []                         []       5  \n",
       "59998              [[0.0, 15.0]]              [[0.0, 10.0]]       6  \n",
       "59999  [[0.0, 20.0], [0.0, 8.0]]  [[0.0, 14.0], [0.0, 5.0]]       8  \n",
       "\n",
       "[60000 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from teaspoon.ML import load_datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "mnist = load_datasets.mnist()\n",
    "mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataset for timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length 3 dgms</th>\n",
       "      <th>Length 6 dgms</th>\n",
       "      <th>Length 10 dgms</th>\n",
       "      <th>Length 20 dmgs</th>\n",
       "      <th>Length 40 dgms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[41, 81], [71, 71], [44, 86]]</td>\n",
       "      <td>[[73, 86], [44, 57], [23, 81], [2, 33], [19, 3...</td>\n",
       "      <td>[[67, 90], [70, 72], [97, 97], [55, 82], [22, ...</td>\n",
       "      <td>[[5, 46], [98, 99], [18, 37], [29, 90], [96, 9...</td>\n",
       "      <td>[[11, 46], [88, 92], [49, 59], [24, 68], [18, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[77, 94], [51, 59], [5, 73]]</td>\n",
       "      <td>[[4, 21], [25, 61], [87, 89], [32, 51], [92, 9...</td>\n",
       "      <td>[[65, 85], [3, 21], [7, 70], [27, 99], [30, 57...</td>\n",
       "      <td>[[62, 64], [76, 78], [5, 26], [72, 82], [71, 9...</td>\n",
       "      <td>[[20, 69], [24, 88], [12, 92], [39, 93], [2, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[56, 96], [21, 60], [66, 66]]</td>\n",
       "      <td>[[17, 75], [85, 90], [3, 20], [15, 81], [9, 16...</td>\n",
       "      <td>[[84, 92], [66, 71], [3, 17], [92, 98], [9, 77...</td>\n",
       "      <td>[[84, 87], [42, 81], [46, 62], [37, 67], [13, ...</td>\n",
       "      <td>[[76, 89], [85, 86], [30, 45], [42, 52], [42, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[14, 91], [80, 99], [13, 71]]</td>\n",
       "      <td>[[52, 85], [75, 76], [46, 87], [12, 12], [39, ...</td>\n",
       "      <td>[[95, 95], [10, 33], [54, 76], [71, 89], [60, ...</td>\n",
       "      <td>[[38, 57], [92, 99], [18, 70], [41, 92], [64, ...</td>\n",
       "      <td>[[87, 96], [41, 90], [43, 44], [28, 74], [16, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[33, 63], [71, 80], [8, 26]]</td>\n",
       "      <td>[[0, 3], [16, 31], [97, 97], [39, 94], [84, 97...</td>\n",
       "      <td>[[5, 27], [44, 54], [25, 41], [41, 51], [90, 9...</td>\n",
       "      <td>[[95, 99], [83, 90], [17, 77], [33, 88], [88, ...</td>\n",
       "      <td>[[54, 90], [24, 84], [99, 99], [96, 99], [5, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[[1, 73], [26, 54], [64, 67]]</td>\n",
       "      <td>[[99, 99], [35, 67], [27, 28], [71, 83], [97, ...</td>\n",
       "      <td>[[83, 90], [67, 93], [6, 20], [58, 62], [38, 7...</td>\n",
       "      <td>[[65, 77], [30, 84], [94, 96], [94, 94], [22, ...</td>\n",
       "      <td>[[85, 94], [55, 82], [79, 90], [62, 75], [79, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[[69, 74], [46, 67], [18, 23]]</td>\n",
       "      <td>[[66, 89], [93, 94], [88, 96], [24, 66], [91, ...</td>\n",
       "      <td>[[13, 24], [32, 36], [12, 89], [8, 45], [74, 9...</td>\n",
       "      <td>[[71, 71], [40, 83], [77, 94], [70, 90], [20, ...</td>\n",
       "      <td>[[39, 86], [41, 93], [66, 79], [56, 75], [1, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[[1, 25], [78, 97], [35, 90]]</td>\n",
       "      <td>[[76, 79], [50, 94], [91, 92], [61, 63], [21, ...</td>\n",
       "      <td>[[90, 91], [26, 48], [86, 97], [82, 88], [21, ...</td>\n",
       "      <td>[[19, 59], [38, 59], [35, 69], [97, 98], [71, ...</td>\n",
       "      <td>[[10, 20], [3, 57], [23, 95], [27, 92], [93, 9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[[9, 17], [38, 62], [77, 81]]</td>\n",
       "      <td>[[7, 97], [61, 61], [52, 89], [21, 27], [19, 5...</td>\n",
       "      <td>[[49, 65], [90, 91], [4, 99], [24, 84], [40, 5...</td>\n",
       "      <td>[[16, 82], [71, 91], [79, 83], [54, 87], [1, 4...</td>\n",
       "      <td>[[56, 80], [3, 50], [58, 79], [16, 58], [28, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[[16, 28], [67, 91], [4, 53]]</td>\n",
       "      <td>[[34, 68], [60, 88], [65, 94], [16, 66], [87, ...</td>\n",
       "      <td>[[59, 74], [93, 98], [20, 52], [53, 96], [93, ...</td>\n",
       "      <td>[[6, 14], [12, 97], [41, 81], [47, 69], [69, 9...</td>\n",
       "      <td>[[60, 76], [70, 98], [41, 70], [52, 64], [40, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Length 3 dgms  \\\n",
       "0    [[41, 81], [71, 71], [44, 86]]   \n",
       "1     [[77, 94], [51, 59], [5, 73]]   \n",
       "2    [[56, 96], [21, 60], [66, 66]]   \n",
       "3    [[14, 91], [80, 99], [13, 71]]   \n",
       "4     [[33, 63], [71, 80], [8, 26]]   \n",
       "..                              ...   \n",
       "995   [[1, 73], [26, 54], [64, 67]]   \n",
       "996  [[69, 74], [46, 67], [18, 23]]   \n",
       "997   [[1, 25], [78, 97], [35, 90]]   \n",
       "998   [[9, 17], [38, 62], [77, 81]]   \n",
       "999   [[16, 28], [67, 91], [4, 53]]   \n",
       "\n",
       "                                         Length 6 dgms  \\\n",
       "0    [[73, 86], [44, 57], [23, 81], [2, 33], [19, 3...   \n",
       "1    [[4, 21], [25, 61], [87, 89], [32, 51], [92, 9...   \n",
       "2    [[17, 75], [85, 90], [3, 20], [15, 81], [9, 16...   \n",
       "3    [[52, 85], [75, 76], [46, 87], [12, 12], [39, ...   \n",
       "4    [[0, 3], [16, 31], [97, 97], [39, 94], [84, 97...   \n",
       "..                                                 ...   \n",
       "995  [[99, 99], [35, 67], [27, 28], [71, 83], [97, ...   \n",
       "996  [[66, 89], [93, 94], [88, 96], [24, 66], [91, ...   \n",
       "997  [[76, 79], [50, 94], [91, 92], [61, 63], [21, ...   \n",
       "998  [[7, 97], [61, 61], [52, 89], [21, 27], [19, 5...   \n",
       "999  [[34, 68], [60, 88], [65, 94], [16, 66], [87, ...   \n",
       "\n",
       "                                        Length 10 dgms  \\\n",
       "0    [[67, 90], [70, 72], [97, 97], [55, 82], [22, ...   \n",
       "1    [[65, 85], [3, 21], [7, 70], [27, 99], [30, 57...   \n",
       "2    [[84, 92], [66, 71], [3, 17], [92, 98], [9, 77...   \n",
       "3    [[95, 95], [10, 33], [54, 76], [71, 89], [60, ...   \n",
       "4    [[5, 27], [44, 54], [25, 41], [41, 51], [90, 9...   \n",
       "..                                                 ...   \n",
       "995  [[83, 90], [67, 93], [6, 20], [58, 62], [38, 7...   \n",
       "996  [[13, 24], [32, 36], [12, 89], [8, 45], [74, 9...   \n",
       "997  [[90, 91], [26, 48], [86, 97], [82, 88], [21, ...   \n",
       "998  [[49, 65], [90, 91], [4, 99], [24, 84], [40, 5...   \n",
       "999  [[59, 74], [93, 98], [20, 52], [53, 96], [93, ...   \n",
       "\n",
       "                                        Length 20 dmgs  \\\n",
       "0    [[5, 46], [98, 99], [18, 37], [29, 90], [96, 9...   \n",
       "1    [[62, 64], [76, 78], [5, 26], [72, 82], [71, 9...   \n",
       "2    [[84, 87], [42, 81], [46, 62], [37, 67], [13, ...   \n",
       "3    [[38, 57], [92, 99], [18, 70], [41, 92], [64, ...   \n",
       "4    [[95, 99], [83, 90], [17, 77], [33, 88], [88, ...   \n",
       "..                                                 ...   \n",
       "995  [[65, 77], [30, 84], [94, 96], [94, 94], [22, ...   \n",
       "996  [[71, 71], [40, 83], [77, 94], [70, 90], [20, ...   \n",
       "997  [[19, 59], [38, 59], [35, 69], [97, 98], [71, ...   \n",
       "998  [[16, 82], [71, 91], [79, 83], [54, 87], [1, 4...   \n",
       "999  [[6, 14], [12, 97], [41, 81], [47, 69], [69, 9...   \n",
       "\n",
       "                                        Length 40 dgms  \n",
       "0    [[11, 46], [88, 92], [49, 59], [24, 68], [18, ...  \n",
       "1    [[20, 69], [24, 88], [12, 92], [39, 93], [2, 9...  \n",
       "2    [[76, 89], [85, 86], [30, 45], [42, 52], [42, ...  \n",
       "3    [[87, 96], [41, 90], [43, 44], [28, 74], [16, ...  \n",
       "4    [[54, 90], [24, 84], [99, 99], [96, 99], [5, 7...  \n",
       "..                                                 ...  \n",
       "995  [[85, 94], [55, 82], [79, 90], [62, 75], [79, ...  \n",
       "996  [[39, 86], [41, 93], [66, 79], [56, 75], [1, 8...  \n",
       "997  [[10, 20], [3, 57], [23, 95], [27, 92], [93, 9...  \n",
       "998  [[56, 80], [3, 50], [58, 79], [16, 58], [28, 8...  \n",
       "999  [[60, 76], [70, 98], [41, 70], [52, 64], [40, ...  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timing_dgms = np.empty([1000,5], dtype=object)\n",
    "for j in range(0,1000):\n",
    "    three_dgms = []\n",
    "    six_dgms = []\n",
    "    ten_dgms = []\n",
    "    twenty_dgms = []\n",
    "    forty_dgms = []\n",
    "    for i in range(0,3):\n",
    "        birth = np.random.randint(0, 100, size=1)\n",
    "        death = np.random.randint(birth, 100, size=1)\n",
    "        point = [birth[0], death[0]]\n",
    "        three_dgms.append(point)\n",
    "    for i in range(0,6):\n",
    "        birth = np.random.randint(0, 100, size=1)\n",
    "        death = np.random.randint(birth, 100, size=1)\n",
    "        point = [birth[0], death[0]]\n",
    "        six_dgms.append(point)\n",
    "    for i in range(0,10):\n",
    "        birth = np.random.randint(0, 100, size=1)\n",
    "        death = np.random.randint(birth, 100, size=1)\n",
    "        point = [birth[0], death[0]]\n",
    "        ten_dgms.append(point)\n",
    "    for i in range(0,20):\n",
    "        birth = np.random.randint(0, 100, size=1)\n",
    "        death = np.random.randint(birth, 100, size=1)\n",
    "        point = [birth[0], death[0]]\n",
    "        twenty_dgms.append(point)\n",
    "    for i in range(0,40):\n",
    "        birth = np.random.randint(0, 100, size=1)\n",
    "        death = np.random.randint(birth, 100, size=1)\n",
    "        point = [birth[0], death[0]]\n",
    "        forty_dgms.append(point)\n",
    "    timing_dgms[j,0]=three_dgms\n",
    "    timing_dgms[j,1]=six_dgms\n",
    "    timing_dgms[j,2]=ten_dgms\n",
    "    timing_dgms[j,3]=twenty_dgms\n",
    "    timing_dgms[j,4]=forty_dgms\n",
    "timing_dgms = pd.DataFrame(timing_dgms)\n",
    "timing_dgms.columns = ['Length 3 dgms', 'Length 6 dgms', 'Length 10 dgms', 'Length 20 dmgs', 'Length 40 dgms']\n",
    "timing_dgms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [[67, 90], [70, 72], [97, 97], [55, 82], [22, ...\n",
       "1      [[65, 85], [3, 21], [7, 70], [27, 99], [30, 57...\n",
       "2      [[84, 92], [66, 71], [3, 17], [92, 98], [9, 77...\n",
       "3      [[95, 95], [10, 33], [54, 76], [71, 89], [60, ...\n",
       "4      [[5, 27], [44, 54], [25, 41], [41, 51], [90, 9...\n",
       "                             ...                        \n",
       "995    [[83, 90], [67, 93], [6, 20], [58, 62], [38, 7...\n",
       "996    [[13, 24], [32, 36], [12, 89], [8, 45], [74, 9...\n",
       "997    [[90, 91], [26, 48], [86, 97], [82, 88], [21, ...\n",
       "998    [[49, 65], [90, 91], [4, 99], [24, 84], [40, 5...\n",
       "999    [[59, 74], [93, 98], [20, 52], [53, 96], [93, ...\n",
       "Name: Length 10 dgms, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timing_dgms['Length 10 dgms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Missing Data in One Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(dim_1):\n",
    "    for i in range(0, len(dim_1)):\n",
    "        if len(dim_1[i])== 0:\n",
    "            dim_1[i] = np.array([[0,.01]])\n",
    "        else: \n",
    "            dim_1[i] = dim_1[i]\n",
    "    return dim_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "mnist['one_dim_rtl'] = fill_missing(mnist['one_dim_rtl'])\n",
    "mnist['one_dim_ltr'] = fill_missing(mnist['one_dim_ltr'])\n",
    "mnist['one_dim_btt'] = fill_missing(mnist['one_dim_btt'])\n",
    "mnist['one_dim_ttb'] = fill_missing(mnist['one_dim_ttb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Dimension for Timing Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_sklearn(DgmsFD, labels_col, train_size=.5, seed=12):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    labels = DgmsFD[labels_col]\n",
    "    training_dgms, testing_dgms = train_test_split(DgmsFD, train_size=train_size, random_state=seed, stratify=labels)\n",
    "    return training_dgms.reset_index(), testing_dgms.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dgms_train, dgms_test = train_test_split_sklearn(mnist, 'labels', train_size = .1)\n",
    "xdgm0_train = dgms_train['zero_dim_rtl']\n",
    "xdgm0_test = dgms_test['zero_dim_rtl']\n",
    "xdgm1_train = dgms_train['one_dim_rtl']\n",
    "xdgm1_test = dgms_test['one_dim_rtl']\n",
    "labels_train = dgms_train['labels']\n",
    "labels_test = dgms_test['labels']\n",
    "len(xdgm0_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load original adaptive features function from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn import mixture\n",
    "import numpy as np\n",
    "\n",
    "def f_dgm(dgm, function, **keyargs):\n",
    "\t'''\n",
    "\tGiven a persistend diagram :math:`D = (S,\\mu)` and a compactly supported function in :math:`\\mathbb{R}^2`, this function computes\n",
    "\t.. math::\n",
    "\t\t\\\\nu_{D}(f) = \\sum_{x\\in S} f(x)\\mu(x)\n",
    "\t:param dgm: persistent diagram, array of points in :math:`\\mathbb{R}^2`.\n",
    "\t:type dgm: Numpy array\n",
    "\t:param function: Compactly supported function in :math:`\\mathbb{R}^2`.\n",
    "\t:type function: function\n",
    "\t:param keyargs: Additional arguments required by `funciton`\n",
    "\t:type keyargs: Dicctionary\n",
    "\t:return: float -- value of :math:`\\\\nu_{D}(f)`.\n",
    "\t'''\n",
    "\n",
    "\ttemp = function(dgm, **keyargs)\n",
    "\n",
    "\treturn sum(temp)\n",
    "\n",
    "def f_ellipse (x, center=np.array([0,0]), axis=np.array([1,1]), rotation=np.array([[1,0],[0,1]])):\n",
    "\t'''\n",
    "\tComputes a bump function centered with an ellipsoidal domain centered ac `c`, rotaded by 'rotation' and with axis given by 'axis'. The bump function is computed using the gollowing formula \n",
    "\t.. math::\n",
    "\t\tf_{A,c} (x) = \\max \\\\left\\{ 0, 1 - (x - c)^T A (x - c)\\\\right\\}\n",
    "\t:param x: point to avelatuate the function :math:`f_{A,c}`\n",
    "\t:type z: Numpy array\n",
    "\t:param center: center of the ellipse\n",
    "\t:type center: Numpy array\n",
    "\t:param axis: Size f themjor an minor axis of the ellipse\n",
    "\t:type axis: Numpy array\n",
    "\t:param rotation: Rotation matrix for the ellipse\n",
    "\t:type rotation: Numpy array\n",
    "\t:return: float -- value of :math:`f_{A,c} (x)`.\n",
    "\t'''\n",
    "\tsigma = np.diag(np.power(axis, -2))\n",
    "\tx_centered = np.subtract(x, center)\n",
    "\ttemp = x_centered@rotation@sigma@np.transpose(rotation)@np.transpose(x_centered)\n",
    "\ttemp = np.diag(temp)\n",
    "\n",
    "\treturn np.maximum(0, 1-temp)\n",
    "def feature(list_dgms, function, **keyargs):\n",
    "\t'''\n",
    "\tGiven a collection of persistent diagrams and a compactly supported function in :math:`\\mathbb{R}^2`, computes :math:`\\\\nu_{D}(f)` for each diagram :math:`D` in the collection.\n",
    "\t:param list_dgms: list of persistent diagrams\n",
    "\t:type list_dgms: list\n",
    "\t:param function: Compactly supported function in :math:`\\mathbb{R}^2`.\n",
    "\t:type function: function\n",
    "\t:param keyargs: Additional arguments required by `funciton`\n",
    "\t:type keyargs: Dicctionary\n",
    "\t:return: Numpy array -- Array of values :math:`\\\\nu_{D}(f)` for each diagram :math:`D` in the collection `list_dgms`.\n",
    "\t'''\n",
    "\tnum_diagrams = len(list_dgms)\n",
    "\n",
    "\tfeat = np.zeros(num_diagrams)\n",
    "\tfor i in range(num_diagrams):\n",
    "\t\tfeat[i] = f_dgm(list_dgms[i], function, **keyargs)\n",
    "\n",
    "\treturn feat\n",
    "\n",
    "def get_all_features(list_dgms, list_ellipses, function):\n",
    "\t'''\n",
    "\tThis function computes all the features for a colelction of persistent diagrams given a list ot ellipses.\n",
    "\t:param list_dgms: list of persistent diagrams\n",
    "\t:type list_dgms: list\n",
    "\t:param list_ellipses: List of dicctionaries. Each dicctionary represents a ellipse. It must have the following keys: `mean`, `std` and `rotation`.\n",
    "\t:type list_ellipses: list\n",
    "\t:param function: Compactly supported function in :math:`\\mathbb{R}^2`.\n",
    "\t:type function: function\n",
    "\t:return: Numpy array -- \n",
    "\t'''\n",
    "\tfeatures = np.zeros((len(list_dgms), len(list_ellipses)))\n",
    "\tfor i in range(len(list_ellipses)):\n",
    "\t\targs = {key:list_ellipses[i][key] for key in ['mean', 'std', 'rotation']}\n",
    "\t\targs['center'] = args.pop('mean')\n",
    "\t\targs['axis'] = args.pop('std')\n",
    "\n",
    "\t\tfeatures[:,i] = feature(list_dgms, function, **args)\n",
    "\n",
    "\treturn features\n",
    "\n",
    "def adaptive_features(X_train, y_train, d=25):\n",
    "\n",
    "\tX_train_temp = np.vstack(X_train)\n",
    "\tgmm_f_train=[]\n",
    "\tfor i in range(len(X_train)):\n",
    "\t\tgmm_f_train.append(y_train[i]*np.ones(len(X_train[i])))\n",
    "\tgmm_f_train = np.concatenate(gmm_f_train)\n",
    "\n",
    "\tgmm = mixture.BayesianGaussianMixture(n_components=d, covariance_type='full', max_iter=int(10e4)).fit(X_train_temp, gmm_f_train)\n",
    "\n",
    "\tellipses = []\n",
    "\tfor i in range(len(gmm.means_)):\n",
    "\t\tL, v = np.linalg.eig(gmm.covariances_[i])\n",
    "\t\ttemp = {'mean':gmm.means_[i], 'std':np.sqrt(L), 'rotation':v.transpose(), 'radius':max(np.sqrt(L)), 'entropy':gmm.weights_[i]}\n",
    "\t\ttemp['std'] = 3*temp['std']\n",
    "\t\tellipses.append(temp)\n",
    "\n",
    "\tX_train_features = get_all_features(X_train, ellipses, f_ellipse)\n",
    "\treturn X_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.4 s Â± 1.72 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "67.7 ms Â± 13.8 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit adaptive_features(xdgm0_train, y_train=labels_train, d=25)\n",
    "%timeit adaptive_features(xdgm0_train[0:100], y_train=labels_train[0:100], d=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p6/pn26dbmx4jj67d6nh7m6557h0000gn/T/ipykernel_50377/3258567730.py:6: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def jit_f_dgm(dgm, function, **keyargs):\n",
      "/var/folders/p6/pn26dbmx4jj67d6nh7m6557h0000gn/T/ipykernel_50377/3258567730.py:25: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def jit_f_ellipse (x, center=np.array([0,0]), axis=np.array([1,1]), rotation=np.array([[1,0],[0,1]])):\n",
      "/var/folders/p6/pn26dbmx4jj67d6nh7m6557h0000gn/T/ipykernel_50377/3258567730.py:48: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def jit_feature(list_dgms, function, **keyargs):\n",
      "/var/folders/p6/pn26dbmx4jj67d6nh7m6557h0000gn/T/ipykernel_50377/3258567730.py:68: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def jit_get_all_features(list_dgms, list_ellipses, function):\n",
      "/var/folders/p6/pn26dbmx4jj67d6nh7m6557h0000gn/T/ipykernel_50377/3258567730.py:90: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def jit_adaptive_features(X_train, y_train, d=25):\n"
     ]
    }
   ],
   "source": [
    "from numba import jit\n",
    "import multiprocessing\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "print(cpu_count)\n",
    "@jit\n",
    "def jit_f_dgm(dgm, function, **keyargs):\n",
    "\t'''\n",
    "\tGiven a persistend diagram :math:`D = (S,\\mu)` and a compactly supported function in :math:`\\mathbb{R}^2`, this function computes\n",
    "\t.. math::\n",
    "\t\t\\\\nu_{D}(f) = \\sum_{x\\in S} f(x)\\mu(x)\n",
    "\t:param dgm: persistent diagram, array of points in :math:`\\mathbb{R}^2`.\n",
    "\t:type dgm: Numpy array\n",
    "\t:param function: Compactly supported function in :math:`\\mathbb{R}^2`.\n",
    "\t:type function: function\n",
    "\t:param keyargs: Additional arguments required by `funciton`\n",
    "\t:type keyargs: Dicctionary\n",
    "\t:return: float -- value of :math:`\\\\nu_{D}(f)`.\n",
    "\t'''\n",
    "\n",
    "\ttemp = function(dgm, **keyargs)\n",
    "\n",
    "\treturn sum(temp)\n",
    "\n",
    "@jit\n",
    "def jit_f_ellipse (x, center=np.array([0,0]), axis=np.array([1,1]), rotation=np.array([[1,0],[0,1]])):\n",
    "\t'''\n",
    "\tComputes a bump function centered with an ellipsoidal domain centered ac `c`, rotaded by 'rotation' and with axis given by 'axis'. The bump function is computed using the gollowing formula \n",
    "\t.. math::\n",
    "\t\tf_{A,c} (x) = \\max \\\\left\\{ 0, 1 - (x - c)^T A (x - c)\\\\right\\}\n",
    "\t:param x: point to avelatuate the function :math:`f_{A,c}`\n",
    "\t:type z: Numpy array\n",
    "\t:param center: center of the ellipse\n",
    "\t:type center: Numpy array\n",
    "\t:param axis: Size f themjor an minor axis of the ellipse\n",
    "\t:type axis: Numpy array\n",
    "\t:param rotation: Rotation matrix for the ellipse\n",
    "\t:type rotation: Numpy array\n",
    "\t:return: float -- value of :math:`f_{A,c} (x)`.\n",
    "\t'''\n",
    "\tsigma = np.diag(np.power(axis, -2))\n",
    "\tx_centered = np.subtract(x, center)\n",
    "\ttemp = x_centered@rotation@sigma@np.transpose(rotation)@np.transpose(x_centered)\n",
    "\ttemp = np.diag(temp)\n",
    "\n",
    "\treturn np.maximum(0, 1-temp)\n",
    "\n",
    "@jit\n",
    "def jit_feature(list_dgms, function, **keyargs):\n",
    "\t'''\n",
    "\tGiven a collection of persistent diagrams and a compactly supported function in :math:`\\mathbb{R}^2`, computes :math:`\\\\nu_{D}(f)` for each diagram :math:`D` in the collection.\n",
    "\t:param list_dgms: list of persistent diagrams\n",
    "\t:type list_dgms: list\n",
    "\t:param function: Compactly supported function in :math:`\\mathbb{R}^2`.\n",
    "\t:type function: function\n",
    "\t:param keyargs: Additional arguments required by `funciton`\n",
    "\t:type keyargs: Dicctionary\n",
    "\t:return: Numpy array -- Array of values :math:`\\\\nu_{D}(f)` for each diagram :math:`D` in the collection `list_dgms`.\n",
    "\t'''\n",
    "\tnum_diagrams = len(list_dgms)\n",
    "\n",
    "\tfeat = np.zeros(num_diagrams)\n",
    "\tfor i in range(num_diagrams):\n",
    "\t\tfeat[i] = f_dgm(list_dgms[i], function, **keyargs)\n",
    "\n",
    "\treturn feat\n",
    "\n",
    "@jit\n",
    "def jit_get_all_features(list_dgms, list_ellipses, function):\n",
    "\t'''\n",
    "\tThis function computes all the features for a colelction of persistent diagrams given a list ot ellipses.\n",
    "\t:param list_dgms: list of persistent diagrams\n",
    "\t:type list_dgms: list\n",
    "\t:param list_ellipses: List of dicctionaries. Each dicctionary represents a ellipse. It must have the following keys: `mean`, `std` and `rotation`.\n",
    "\t:type list_ellipses: list\n",
    "\t:param function: Compactly supported function in :math:`\\mathbb{R}^2`.\n",
    "\t:type function: function\n",
    "\t:return: Numpy array -- \n",
    "\t'''\n",
    "\tfeatures = np.zeros((len(list_dgms), len(list_ellipses)))\n",
    "\tfor i in range(len(list_ellipses)):\n",
    "\t\targs = {key:list_ellipses[i][key] for key in ['mean', 'std', 'rotation']}\n",
    "\t\targs['center'] = args.pop('mean')\n",
    "\t\targs['axis'] = args.pop('std')\n",
    "\n",
    "\t\tfeatures[:,i] = feature(list_dgms, function, **args)\n",
    "\n",
    "\treturn features\n",
    "\n",
    "@jit\n",
    "def jit_adaptive_features(X_train, y_train, d=25):\n",
    "\n",
    "\tX_train_temp = np.vstack(X_train)\n",
    "\tgmm_f_train=[]\n",
    "\tfor i in range(len(X_train)):\n",
    "\t\tgmm_f_train.append(y_train[i]*np.ones(len(X_train[i])))\n",
    "\tgmm_f_train = np.concatenate(gmm_f_train)\n",
    "\n",
    "\tgmm = mixture.BayesianGaussianMixture(n_components=d, covariance_type='full', max_iter=int(10e4)).fit(X_train_temp, gmm_f_train)\n",
    "\n",
    "\tellipses = []\n",
    "\tfor i in range(len(gmm.means_)):\n",
    "\t\tL, v = np.linalg.eig(gmm.covariances_[i])\n",
    "\t\ttemp = {'mean':gmm.means_[i], 'std':np.sqrt(L), 'rotation':v.transpose(), 'radius':max(np.sqrt(L)), 'entropy':gmm.weights_[i]}\n",
    "\t\ttemp['std'] = 3*temp['std']\n",
    "\t\tellipses.append(temp)\n",
    "\n",
    "\tX_train_features = get_all_features(X_train, ellipses, f_ellipse)\n",
    "\treturn X_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.7 ms Â± 19.4 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n",
      "76.6 ms Â± 11 ms per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "#%timeit adaptive_features(xdgm0_train, y_train=labels_train, d=25)\n",
    "%timeit adaptive_features(xdgm0_train[0:100], y_train=labels_train[0:100], d=25)\n",
    "%timeit jit_adaptive_features(xdgm0_train[0:100], y_train=labels_train[0:100], d=25)\n",
    "#%timeit jit_adaptive_features(xdgm0_train, y_train=labels_train, d=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "print(cpu_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimized with Numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy.linalg import norm as lnorm\n",
    "from math import pi\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "@jit\n",
    "def optimizedKernelMethod(perDgm1, perDgm2, sigma):\n",
    "    L1 = len(perDgm1)\n",
    "    L2 = len(perDgm2)\n",
    "    kernel = np.zeros((L2, L1))\n",
    "\n",
    "    Kernel = 0\n",
    "\n",
    "    for i in range(0, L1):\n",
    "        p = perDgm1[i]\n",
    "        p = np.reshape(p, (2, 1))\n",
    "        for j in range(0, L2):\n",
    "            q = perDgm2[j]\n",
    "            q = np.reshape(q, (2, 1))\n",
    "            q_bar = np.zeros((2, 1))\n",
    "            q_bar[0] = q[1]\n",
    "            q_bar[1] = q[0]\n",
    "            dist1 = lnorm(p-q)\n",
    "            dist2 = lnorm(p-q_bar)\n",
    "            kernel[j, i] = np.exp(-(math.pow(dist1, 2))/(8*sigma)) - \\\n",
    "                np.exp(-(math.pow(dist2, 2))/(8*sigma))\n",
    "            Kernel = Kernel+kernel[j, i]\n",
    "    Kernel = Kernel*(1/(8*pi*sigma))\n",
    "\n",
    "    return Kernel\n",
    "\n",
    "@jit\n",
    "def optimized_heat_kernel_distance(dgm0, dgm1, sigma=.4):\n",
    "    return np.sqrt(optimizedKernelMethod(dgm0, dgm0, sigma) + optimizedKernelMethod(dgm1, dgm1, sigma) - 2*optimizedKernelMethod(dgm0, dgm1, sigma))\n",
    "\n",
    "@jit\n",
    "def optimized_kernel_features(train, s):\n",
    "    n_train = len(train)\n",
    "    X_train_features = np.zeros((n_train, n_train))\n",
    "    \n",
    "    for i in range(0,n_train):\n",
    "        for j in range(0,i):\n",
    "            dgm0 = train[i]\n",
    "            dgm1 = train[j]\n",
    "            hka = optimized_heat_kernel_distance(dgm0, dgm1, sigma = s) \n",
    "            X_train_features[i,j] = hka\n",
    "            X_train_features[j,i] = hka\n",
    "\n",
    "    return X_train_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel with jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from numpy.linalg import norm as lnorm\n",
    "from math import pi\n",
    "from numba import jit\n",
    "import time\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def par_optimized_kernel_features(train, s):\n",
    "    n_train = len(train)\n",
    "    for i in range(n_train):\n",
    "        for j in range(i):\n",
    "            dgm0 = train[train[:,0]==i,1:3]\n",
    "            dgm1 = train[train[:,0]==j,1:3]\n",
    "            kSigma0 = 0\n",
    "            kSigma1 = 0\n",
    "            kSigma2 = 0\n",
    "            sigma = s\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm0.shape[0]):\n",
    "                    q = dgm0[l,0:2]\n",
    "                    qc = dgm0[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma0 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm1.shape[0]):\n",
    "                p = dgm1[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma1 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma2 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "\n",
    "            kSigma0 = kSigma0/(8 * np.pi * sigma)\n",
    "            kSigma1 = kSigma1/(8 * np.pi * sigma)\n",
    "            kSigma2 = kSigma2/(8 * np.pi * sigma)\n",
    "            result[i,j] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)\n",
    "            result[j,i] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import guvectorize\n",
    "@guvectorize([\"void(float64[:,:], float64[:], float64, float64[:,:])\",],\"(m,n),(p),()->(p,p)\", target='parallel')\n",
    "def parallel_kernel_features_train(train, dummy, s, result):\n",
    "    n_train = len(dummy)\n",
    "    for i in range(n_train):\n",
    "        for j in range(i):\n",
    "            dgm0 = train[train[:,0]==i,1:3]\n",
    "            dgm1 = train[train[:,0]==j,1:3]\n",
    "            kSigma0 = 0\n",
    "            kSigma1 = 0\n",
    "            kSigma2 = 0\n",
    "            sigma = s\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm0.shape[0]):\n",
    "                    q = dgm0[l,0:2]\n",
    "                    qc = dgm0[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma0 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm1.shape[0]):\n",
    "                p = dgm1[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma1 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma2 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "\n",
    "            kSigma0 = kSigma0/(8 * np.pi * sigma)\n",
    "            kSigma1 = kSigma1/(8 * np.pi * sigma)\n",
    "            kSigma2 = kSigma2/(8 * np.pi * sigma)\n",
    "            result[i,j] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)\n",
    "            result[j,i] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import guvectorize\n",
    "@guvectorize([\"void(float64[:,:], float64[:], float64, float64[:,:])\",],\"(m,n),(p),()->(p,p)\", target='cpu')\n",
    "def gu_kernel_features_train(train, dummy, s, result):\n",
    "    n_train = len(dummy)\n",
    "    for i in range(n_train):\n",
    "        for j in range(i):\n",
    "            dgm0 = train[train[:,0]==i,1:3]\n",
    "            dgm1 = train[train[:,0]==j,1:3]\n",
    "            kSigma0 = 0\n",
    "            kSigma1 = 0\n",
    "            kSigma2 = 0\n",
    "            sigma = s\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm0.shape[0]):\n",
    "                    q = dgm0[l,0:2]\n",
    "                    qc = dgm0[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma0 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm1.shape[0]):\n",
    "                p = dgm1[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma1 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "            for k in range(dgm0.shape[0]):\n",
    "                p = dgm0[k,0:2]\n",
    "                for l in range(dgm1.shape[0]):\n",
    "                    q = dgm1[l,0:2]\n",
    "                    qc = dgm1[l, 1::-1]\n",
    "                    pq = (p[0] - q[0])**2 + (p[1] - q[1])**2\n",
    "                    pqc = (p[0] - qc[0])**2 + (p[1] - qc[1])**2\n",
    "                    kSigma2 += math.exp(-( pq) / (8 * sigma)) - math.exp(-(pqc) / (8 * sigma))\n",
    "\n",
    "            kSigma0 = kSigma0/(8 * np.pi * sigma)\n",
    "            kSigma1 = kSigma1/(8 * np.pi * sigma)\n",
    "            kSigma2 = kSigma2/(8 * np.pi * sigma)\n",
    "            result[i,j] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)\n",
    "            result[j,i] = math.sqrt(kSigma1 + kSigma0-2*kSigma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_persistence_diagrams(dgm):\n",
    "    dgm_reshape = np.array([])\n",
    "    n = len(dgm)\n",
    "    for i in range(0,n):\n",
    "        t = np.repeat(i, len(dgm[i]))\n",
    "        t = t.reshape(len(dgm[i]),1)\n",
    "        t1 = np.concatenate((t,dgm[i]),1)\n",
    "        if i == 0:\n",
    "            dgm_reshape = t1\n",
    "        else:\n",
    "            dgm_reshape = np.append(dgm_reshape, t1, 0)\n",
    "    return dgm_reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run to compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms_train, dgms_test = train_test_split_sklearn(mnist, 'labels', train_size = 10, seed=1)\n",
    "train_test = np.array(dgms_train['zero_dim_rtl'])\n",
    "X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "dummy_train = np.arange(len(train_test), dtype=np.float64)\n",
    "train = reshape_persistence_diagrams(train_test)\n",
    "result = parallel_kernel_features_train(train, dummy_train, .3)\n",
    "#X_train_features = par_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop for random samples and timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training  0\n",
      "Finished Training  1\n",
      "Finished Training  2\n"
     ]
    }
   ],
   "source": [
    "seed = [0,1,2,3,4,5,6,7,8,9]\n",
    "train_size = [.001, .005, .01, .05] # .01, .05]\n",
    "n = len(train_size)\n",
    "timing = np.zeros((n,4))\n",
    "for i in range(0,n):\n",
    "    for j in seed:\n",
    "        dgms_train, dgms_test = train_test_split_sklearn(mnist, 'labels', train_size = train_size[i], seed=j)\n",
    "        xdgm0_train = np.array(dgms_train['zero_dim_rtl'])\n",
    "        dummy_train = np.arange(len(xdgm0_train), dtype=np.float64)\n",
    "        train = reshape_persistence_diagrams(xdgm0_train)\n",
    "        timing[i,0] += len(xdgm0_train)\n",
    "\n",
    "        start = time.time()\n",
    "        result1 = gu_kernel_features_train(train, dummy_train, .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,1] +=end\n",
    "\n",
    "        start = time.time()\n",
    "        X_train_features = optimized_kernel_features(xdgm0_train, s = .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,2] +=end\n",
    "        start = time.time()\n",
    "        result3 = parallel_kernel_features_train(train, dummy_train, .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,3] +=end\n",
    "    print(\"Finished Training \", i)\n",
    "timing = pd.DataFrame(timing/10)\n",
    "timing.columns=['Observations', 'guvectorize', 'Jit optimized', 'Vectorized and Threading']\n",
    "print(timing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training  0\n",
      "Finished Training  1\n",
      "Finished Training  2\n",
      "Finished Training  3\n",
      "   Observations    Original  Jit optimized  Vectorized and Threading\n",
      "0          60.0    0.104926       0.010555                  0.001208\n",
      "1         300.0    2.637221       0.252662                  0.062772\n",
      "2         600.0   10.669852       1.033499                  0.413544\n",
      "3        3000.0  270.665288      27.861426                 46.286630\n"
     ]
    }
   ],
   "source": [
    "seed = [0,1,2,3,4,5,6,7,8,9]\n",
    "train_size = [.001, .005, .01, .05]\n",
    "n = len(train_size)\n",
    "timing = np.zeros((n,4))\n",
    "for i in range(0,n):\n",
    "    for j in seed:\n",
    "        dgms_train, dgms_test = train_test_split_sklearn(mnist, 'labels', train_size = train_size[i], seed=j)\n",
    "        xdgm0_train = np.array(dgms_train['zero_dim_rtl'])\n",
    "        timing[i,0] += len(xdgm0_train)\n",
    "        start = time.time()\n",
    "        X_train_features1 = kernel_features(xdgm0_train, s = .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,1] +=end\n",
    "        start = time.time()\n",
    "        X_train_features = optimized_kernel_features(xdgm0_train, s = .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,2] +=end\n",
    "        dummy_train = np.arange(len(xdgm0_train), dtype=np.float64)\n",
    "        train = reshape_persistence_diagrams(xdgm0_train)\n",
    "        start = time.time()\n",
    "        result3 = parallel_kernel_features_train(train, dummy_train, .3)\n",
    "        end = time.time()-start\n",
    "        timing[i,3] +=end\n",
    "    print(\"Finished Training \", i)\n",
    "timing = pd.DataFrame(timing/10)\n",
    "timing.columns=['Observations', 'Original', 'Jit optimized', 'Vectorized and Threading']\n",
    "print(timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threading layer chosen: workqueue\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Threading layer chosen: %s\" % threading_layer())\n",
    "print(config.NUMBA_NUM_THREADS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45 s Â± 12.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "120 ms Â± 416 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n",
      "22.1 ms Â± 604 Âµs per loop (mean Â± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:200]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "dummy_train = np.arange(len(train_test), dtype=np.float64)\n",
    "train = reshape_persistence_diagrams(train_test)\n",
    "%timeit numba_kernel_features_train(train, dummy_train, .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.24 s Â± 41.4 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "272 ms Â± 20.5 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "263 ms Â± 2.62 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:300]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.79 s Â± 114 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "468 ms Â± 2.24 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "466 ms Â± 774 Âµs per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:400]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.06 s Â± 238 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "731 ms Â± 10.7 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "729 ms Â± 7.56 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:500]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.1 s Â± 152 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "1.71 s Â± 143 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "1.66 s Â± 37.7 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:750]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.9 s Â± 773 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "2.98 s Â± 27 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "2.97 s Â± 12.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:1000]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.4 s Â± 524 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "4.67 s Â± 34.3 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "4.68 s Â± 24.4 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:1250]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 20s Â± 761 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "6.78 s Â± 81.8 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n",
      "6.81 s Â± 141 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:1500]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_test \u001b[39m=\u001b[39m xdgm0_train[\u001b[39m0\u001b[39m:\u001b[39m2000\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mtimeit\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtiming, X_train_features = kernel_features(np.array(train_test), s = .3)\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mtimeit\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtiming, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mtimeit\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtiming, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/development/teaspoon/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2417\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2415\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2416\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2417\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2419\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2420\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2421\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/development/teaspoon/.venv/lib/python3.9/site-packages/IPython/core/magics/execution.py:1170\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1168\u001b[0m \u001b[39mfor\u001b[39;00m index \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m):\n\u001b[1;32m   1169\u001b[0m     number \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m index\n\u001b[0;32m-> 1170\u001b[0m     time_number \u001b[39m=\u001b[39m timer\u001b[39m.\u001b[39;49mtimeit(number)\n\u001b[1;32m   1171\u001b[0m     \u001b[39mif\u001b[39;00m time_number \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m:\n\u001b[1;32m   1172\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/development/teaspoon/.venv/lib/python3.9/site-packages/IPython/core/magics/execution.py:158\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    156\u001b[0m gc\u001b[39m.\u001b[39mdisable()\n\u001b[1;32m    157\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     timing \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minner(it, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimer)\n\u001b[1;32m    159\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[39mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[1;32m/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m dgm0 \u001b[39m=\u001b[39m train[i]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m dgm1 \u001b[39m=\u001b[39m train[j]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m hka \u001b[39m=\u001b[39m heat_kernel_distance(dgm0, dgm1, sigma \u001b[39m=\u001b[39;49m s) \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m X_train_features[i,j] \u001b[39m=\u001b[39m hka\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m X_train_features[j,i] \u001b[39m=\u001b[39m hka\n",
      "\u001b[1;32m/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb Cell 21\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mheat_kernel_distance\u001b[39m(dgm0, dgm1, sigma\u001b[39m=\u001b[39m\u001b[39m.4\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msqrt(KernelMethod(dgm0, dgm0, sigma) \u001b[39m+\u001b[39m KernelMethod(dgm1, dgm1, sigma) \u001b[39m-\u001b[39m \u001b[39m2\u001b[39m\u001b[39m*\u001b[39mKernelMethod(dgm0, dgm1, sigma))\n",
      "\u001b[1;32m/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb Cell 21\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m q_bar[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m q[\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m q_bar[\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m q[\u001b[39m0\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m dist1 \u001b[39m=\u001b[39m lnorm(p\u001b[39m-\u001b[39;49mq)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m dist2 \u001b[39m=\u001b[39m lnorm(p\u001b[39m-\u001b[39mq_bar)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m kernel[j, i] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m(math\u001b[39m.\u001b[39mpow(dist1, \u001b[39m2\u001b[39m))\u001b[39m/\u001b[39m(\u001b[39m8\u001b[39m\u001b[39m*\u001b[39msigma)) \u001b[39m-\u001b[39m \\\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniellebarnes/development/teaspoon/notebooks/ml_methods_timing.ipynb#Y114sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m(math\u001b[39m.\u001b[39mpow(dist2, \u001b[39m2\u001b[39m))\u001b[39m/\u001b[39m(\u001b[39m8\u001b[39m\u001b[39m*\u001b[39msigma))\n",
      "File \u001b[0;32m~/development/teaspoon/.venv/lib/python3.9/site-packages/numpy/linalg/linalg.py:2553\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2551\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2552\u001b[0m     sqnorm \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mdot(x)\n\u001b[0;32m-> 2553\u001b[0m ret \u001b[39m=\u001b[39m sqrt(sqnorm)\n\u001b[1;32m   2554\u001b[0m \u001b[39mif\u001b[39;00m keepdims:\n\u001b[1;32m   2555\u001b[0m     ret \u001b[39m=\u001b[39m ret\u001b[39m.\u001b[39mreshape(ndim\u001b[39m*\u001b[39m[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_test = xdgm0_train[0:2000]\n",
    "%timeit timing, X_train_features = kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = optimized_kernel_features(np.array(train_test), s = .3)\n",
    "%timeit timing, X_train_features = parallel_optimized_kernel_features(np.array(train_test), s = .3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
